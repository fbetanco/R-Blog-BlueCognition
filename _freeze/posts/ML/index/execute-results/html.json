{
  "hash": "482dec6be64faea41ed8cdf368b4be9f",
  "result": {
    "markdown": "---\ntitle: \"Spotify Songs Streaming Prediction\"\nauthor: \"Felix Betancourt\"\ndate: \"2/1/2024\"\ncategories: [spotify, machine learning, regression, classification]\n---\n\n\n![](spotify.jpg)\n\n\n# Section 1 - Motivation\n\nAs an avid music listener in general, I have always been curious about the impact of streaming platforms on the music industry in terms of how it has been changing the way people consume, distribute, and monetize music.\n\nThe shift from ownership to access has led to a more consumption-based model, democratized access to music, and enhanced music discoverability. Streaming platforms typically pay artists and rights holders based on the number of streams their songs accumulate.\n\nIn this context, one of the most important impacts of the streaming platform is on the revenue streams, which have been transformed significantly: **the number of streams is becoming the dominant source of income for many artists.**\n\nStreaming platforms generate vast amounts of data on listener behavior, preferences, and trends. This data has become invaluable for artists, labels, and streaming services in understanding audience demographics, optimizing marketing strategies, and identifying opportunities for promotion and monetization.\n\nSo, predicting total streams allows stakeholders to forecast. The ability to predict the total number of streams a song can get is crucial for several reasons:\n\n1.  First, it helps forecast potential revenue streams from a particular track, which is particularly important for budgeting, planning promotional activities, and making financial decisions.\n\n2.  The total number of streams is a critical metric for evaluating the performance and popularity of a song. By predicting future streams, artists, record labels, and streaming platforms can assess the success of a release and compare it to past performances.\n\n    This information is essential for understanding audience preferences and adjusting strategies accordingly.\n\n3.  Predicting total streams enables targeted marketing and promotional efforts, as it helps identify songs likely to garner high stream counts.\n\n4.  Finally, streaming platforms often curate playlists based on predicted popularity and user preferences. Predicting total streams helps platforms identify which songs will likely resonate with their users/audience, leading to better playlist curation therefore increased user engagement.\n\nOverall, the ability to predict total streams for a song provides valuable insights for various stakeholders in the music industry, helping them make informed decisions and optimize their strategies for successful potential revenue streams from a particular track.\n\nThe amount of data sourced by user behaviors and features of the songs, all captured by streaming platforms, is very rich. These data make it feasible to predict the volume of streams through algorithms that will help improve engagement, resulting in maximization of consumption and revenue.\n\nIn all this context, I will use a dataset available in [Kaggle (Spotify 2023 data)](https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023) that contains real data about streaming volumes in Spotify and many features of the songs. I'll use this dataset to create a model that best predict the number of streams for the songs.\n\n::: callout-tip\n### The author describes the dataset as follows:\n\n*\"This dataset contains a comprehensive list of the most famous songs of 2023 as listed on Spotify. The dataset offers a wealth of features beyond what is typically available in similar datasets. It provides insights into each song's attributes, popularity, and presence on various music platforms. The dataset includes information such as track name, artist(s) name, release date, Spotify playlists and charts, streaming statistics, Apple Music presence, Deezer presence, Shazam charts, and various audio features.\"*\n:::\n\n# Section 2 - Exploratory Data Analysis\n\nFirst I'll load packages and read and create the dataset object:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading packages\nsuppressPackageStartupMessages(library(tidyverse, warn.conflicts = FALSE))\nsuppressWarnings(library(dplyr, warn.conflicts = FALSE))\nsuppressWarnings(library(data.table, warn.conflicts = FALSE))\nsuppressWarnings(library(Metrics))\nsuppressWarnings(library(scales, warn.conflicts = FALSE))\nsuppressWarnings(library(formattable, warn.conflicts = FALSE))\nsuppressWarnings(library(kableExtra, warn.conflicts = FALSE))\nsuppressWarnings(library(ggplot2, warn.conflicts = FALSE))\nsuppressWarnings(library(psych, warn.conflicts = FALSE))\nsuppressWarnings(library(summarytools, warn.conflicts = FALSE))\nsuppressWarnings(library(caret, warn.conflicts = FALSE))\nsuppressWarnings(library(corrplot, warn.conflicts = FALSE))\nsuppressWarnings(library(ggpubr, warn.conflicts = FALSE))\nsuppressWarnings(library(tinytex, warn.conflicts = FALSE))\nsuppressWarnings(library(tidymodels, warn.conflicts = FALSE))\nsuppressWarnings(library(glmnet,  warn.conflicts = FALSE))\nsuppressWarnings(library(randomForest, warn.conflicts = FALSE))\nsuppressWarnings(library(e1071, warn.conflicts = FALSE))\nsuppressWarnings(library(ranger, warn.conflicts = FALSE))\n\nconflicted::conflicts_prefer(yardstick::accuracy)\nconflicted::conflicts_prefer(Metrics::mae)\ntidymodels:: tidymodels_prefer(quiet = TRUE) \n\n# Loading the data.\n\nspotify <- read.csv(\"C:/Users/fbeta/OneDrive/Blue Cognition/Blog/R-Blog-BlueCognition/data/spotify-2023.csv\")\n```\n:::\n\n\n## Section 2.1 - Data Cleaning\n\nLet's see what is in the dataset train file and do some data wrangling as needed and avoiding data leakage.\n\nFirst, I found that the author of the data describe the deifnition of each feature in the dataset:\n\ntrack_name: Name of the song artist(s)\n\nname: Name of the artist(s) of the song\n\nartist_count: Number of artists contributing to the song\n\nreleased_year: Year when the song was released\n\nreleased_month: Month when the song was released\n\nreleased_day: Day of the month when the song was released\n\nin_spotify_playlists: Number of Spotify playlists the song is included in\n\nin_spotify_charts: Presence and rank of the song on Spotify charts\n\nstreams: Total number of streams on Spotify\n\nin_apple_playlists: Number of Apple Music playlists the song is included\n\nin in_apple_charts: Presence and rank of the song on Apple Music charts\n\nin_deezer_playlists: Number of Deezer playlists the song is included in\n\nin_deezer_charts: Presence and rank of the song on Deezer charts\n\nin_shazam_charts: Presence and rank of the song on Shazam charts\n\nbpm: Beats per minute, a measure of song tempo\n\nkey: Key of the song\n\nmode: Mode of the song (major or minor)\n\ndanceability\\_%: Percentage indicating how suitable the song is for dancing\n\nvalence\\_%: Positivity of the song's musical content\n\nenergy\\_%: Perceived energy level of the song\n\nacousticness\\_%: Amount of acoustic sound in the song\n\ninstrumentalness\\_%: Amount of instrumental content in the song\n\nliveness\\_%: Presence of live performance elements\n\nspeechiness\\_%: Amount of spoken words in the song\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Structure and summary of the data\n\nstr(spotify)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t953 obs. of  24 variables:\n $ track_name          : chr  \"Seven (feat. Latto) (Explicit Ver.)\" \"LALA\" \"vampire\" \"Cruel Summer\" ...\n $ artist.s._name      : chr  \"Latto, Jung Kook\" \"Myke Towers\" \"Olivia Rodrigo\" \"Taylor Swift\" ...\n $ artist_count        : int  2 1 1 1 1 2 2 1 1 2 ...\n $ released_year       : int  2023 2023 2023 2019 2023 2023 2023 2023 2023 2023 ...\n $ released_month      : int  7 3 6 8 5 6 3 7 5 3 ...\n $ released_day        : int  14 23 30 23 18 1 16 7 15 17 ...\n $ in_spotify_playlists: int  553 1474 1397 7858 3133 2186 3090 714 1096 2953 ...\n $ in_spotify_charts   : int  147 48 113 100 50 91 50 43 83 44 ...\n $ streams             : chr  \"141381703\" \"133716286\" \"140003974\" \"800840817\" ...\n $ in_apple_playlists  : int  43 48 94 116 84 67 34 25 60 49 ...\n $ in_apple_charts     : int  263 126 207 207 133 213 222 89 210 110 ...\n $ in_deezer_playlists : chr  \"45\" \"58\" \"91\" \"125\" ...\n $ in_deezer_charts    : int  10 14 14 12 15 17 13 13 11 13 ...\n $ in_shazam_charts    : chr  \"826\" \"382\" \"949\" \"548\" ...\n $ bpm                 : int  125 92 138 170 144 141 148 100 130 170 ...\n $ key                 : chr  \"B\" \"C#\" \"F\" \"A\" ...\n $ mode                : chr  \"Major\" \"Major\" \"Major\" \"Major\" ...\n $ danceability_.      : int  80 71 51 55 65 92 67 67 85 81 ...\n $ valence_.           : int  89 61 32 58 23 66 83 26 22 56 ...\n $ energy_.            : int  83 74 53 72 80 58 76 71 62 48 ...\n $ acousticness_.      : int  31 7 17 11 14 19 48 37 12 21 ...\n $ instrumentalness_.  : int  0 0 0 0 63 0 0 0 0 0 ...\n $ liveness_.          : int  8 10 31 11 11 8 8 11 28 8 ...\n $ speechiness_.       : int  4 4 6 15 6 24 3 4 9 33 ...\n```\n:::\n\n```{.r .cell-code}\nsummary(spotify)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  track_name        artist.s._name      artist_count   released_year \n Length:953         Length:953         Min.   :1.000   Min.   :1930  \n Class :character   Class :character   1st Qu.:1.000   1st Qu.:2020  \n Mode  :character   Mode  :character   Median :1.000   Median :2022  \n                                       Mean   :1.556   Mean   :2018  \n                                       3rd Qu.:2.000   3rd Qu.:2022  \n                                       Max.   :8.000   Max.   :2023  \n released_month    released_day   in_spotify_playlists in_spotify_charts\n Min.   : 1.000   Min.   : 1.00   Min.   :   31        Min.   :  0.00   \n 1st Qu.: 3.000   1st Qu.: 6.00   1st Qu.:  875        1st Qu.:  0.00   \n Median : 6.000   Median :13.00   Median : 2224        Median :  3.00   \n Mean   : 6.034   Mean   :13.93   Mean   : 5200        Mean   : 12.01   \n 3rd Qu.: 9.000   3rd Qu.:22.00   3rd Qu.: 5542        3rd Qu.: 16.00   \n Max.   :12.000   Max.   :31.00   Max.   :52898        Max.   :147.00   \n   streams          in_apple_playlists in_apple_charts  in_deezer_playlists\n Length:953         Min.   :  0.00     Min.   :  0.00   Length:953         \n Class :character   1st Qu.: 13.00     1st Qu.:  7.00   Class :character   \n Mode  :character   Median : 34.00     Median : 38.00   Mode  :character   \n                    Mean   : 67.81     Mean   : 51.91                      \n                    3rd Qu.: 88.00     3rd Qu.: 87.00                      \n                    Max.   :672.00     Max.   :275.00                      \n in_deezer_charts in_shazam_charts        bpm            key           \n Min.   : 0.000   Length:953         Min.   : 65.0   Length:953        \n 1st Qu.: 0.000   Class :character   1st Qu.:100.0   Class :character  \n Median : 0.000   Mode  :character   Median :121.0   Mode  :character  \n Mean   : 2.666                      Mean   :122.5                     \n 3rd Qu.: 2.000                      3rd Qu.:140.0                     \n Max.   :58.000                      Max.   :206.0                     \n     mode           danceability_.    valence_.        energy_.    \n Length:953         Min.   :23.00   Min.   : 4.00   Min.   : 9.00  \n Class :character   1st Qu.:57.00   1st Qu.:32.00   1st Qu.:53.00  \n Mode  :character   Median :69.00   Median :51.00   Median :66.00  \n                    Mean   :66.97   Mean   :51.43   Mean   :64.28  \n                    3rd Qu.:78.00   3rd Qu.:70.00   3rd Qu.:77.00  \n                    Max.   :96.00   Max.   :97.00   Max.   :97.00  \n acousticness_.  instrumentalness_.   liveness_.    speechiness_.  \n Min.   : 0.00   Min.   : 0.000     Min.   : 3.00   Min.   : 2.00  \n 1st Qu.: 6.00   1st Qu.: 0.000     1st Qu.:10.00   1st Qu.: 4.00  \n Median :18.00   Median : 0.000     Median :12.00   Median : 6.00  \n Mean   :27.06   Mean   : 1.581     Mean   :18.21   Mean   :10.13  \n 3rd Qu.:43.00   3rd Qu.: 0.000     3rd Qu.:24.00   3rd Qu.:11.00  \n Max.   :97.00   Max.   :91.000     Max.   :97.00   Max.   :64.00  \n```\n:::\n:::\n\n\nI will make some obvious adjustments to certain variables, for example the number of \"streams\" have to be numeric, for some reason it is set as character. Also I'll fix some features names in the dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Mutating to numeric variables that should be numeric (streams\n\nspotify$streams <- as.numeric(spotify$streams)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: NAs introduced by coercion\n```\n:::\n\n```{.r .cell-code}\nspotify$in_deezer_playlists <- as.numeric(spotify$in_deezer_playlists)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: NAs introduced by coercion\n```\n:::\n\n```{.r .cell-code}\nspotify$in_shazam_charts <- as.numeric(spotify$in_shazam_charts)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: NAs introduced by coercion\n```\n:::\n\n```{.r .cell-code}\n#I'll remove special characters from Artist name and track name. \n\nspotify <- spotify %>% mutate(artist.s._name = str_remove_all(artist.s._name, \"[^[:alnum:]]\"))\nspotify <- spotify %>% mutate(track_name = str_remove_all(track_name, \"[^[:alnum:]]\"))\n\n# Now I'll create an ID column by merging these 2 columns\n\nspotify$id <- paste(spotify$track_name, spotify$artist.s._name)\n\n#Eliminating spaces\n\nspotify <- spotify %>% mutate(id = str_remove_all(id, \"[^[:alnum:]]\"))\n\n#Renaming some features names to facilitate the coding later\n\nspotify <- rename(spotify, artist.name = artist.s._name, number.art.song = artist_count, danceability = danceability_., valence = valence_., energy = energy_., acousticness = acousticness_., instrumentalness = instrumentalness_., liveness = liveness_., speechiness = speechiness_.)\n\n\n#Let's check how the df looks now\ndim(spotify)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 953  25\n```\n:::\n\n```{.r .cell-code}\nsummary(spotify)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  track_name        artist.name        number.art.song released_year \n Length:953         Length:953         Min.   :1.000   Min.   :1930  \n Class :character   Class :character   1st Qu.:1.000   1st Qu.:2020  \n Mode  :character   Mode  :character   Median :1.000   Median :2022  \n                                       Mean   :1.556   Mean   :2018  \n                                       3rd Qu.:2.000   3rd Qu.:2022  \n                                       Max.   :8.000   Max.   :2023  \n                                                                     \n released_month    released_day   in_spotify_playlists in_spotify_charts\n Min.   : 1.000   Min.   : 1.00   Min.   :   31        Min.   :  0.00   \n 1st Qu.: 3.000   1st Qu.: 6.00   1st Qu.:  875        1st Qu.:  0.00   \n Median : 6.000   Median :13.00   Median : 2224        Median :  3.00   \n Mean   : 6.034   Mean   :13.93   Mean   : 5200        Mean   : 12.01   \n 3rd Qu.: 9.000   3rd Qu.:22.00   3rd Qu.: 5542        3rd Qu.: 16.00   \n Max.   :12.000   Max.   :31.00   Max.   :52898        Max.   :147.00   \n                                                                        \n    streams          in_apple_playlists in_apple_charts  in_deezer_playlists\n Min.   :2.762e+03   Min.   :  0.00     Min.   :  0.00   Min.   :  0.0      \n 1st Qu.:1.416e+08   1st Qu.: 13.00     1st Qu.:  7.00   1st Qu.: 12.0      \n Median :2.905e+08   Median : 34.00     Median : 38.00   Median : 36.5      \n Mean   :5.141e+08   Mean   : 67.81     Mean   : 51.91   Mean   :109.7      \n 3rd Qu.:6.739e+08   3rd Qu.: 88.00     3rd Qu.: 87.00   3rd Qu.:110.0      \n Max.   :3.704e+09   Max.   :672.00     Max.   :275.00   Max.   :974.0      \n NA's   :1                                               NA's   :79         \n in_deezer_charts in_shazam_charts      bpm            key           \n Min.   : 0.000   Min.   :  0.00   Min.   : 65.0   Length:953        \n 1st Qu.: 0.000   1st Qu.:  0.00   1st Qu.:100.0   Class :character  \n Median : 0.000   Median :  2.00   Median :121.0   Mode  :character  \n Mean   : 2.666   Mean   : 51.18   Mean   :122.5                     \n 3rd Qu.: 2.000   3rd Qu.: 36.00   3rd Qu.:140.0                     \n Max.   :58.000   Max.   :953.00   Max.   :206.0                     \n                  NA's   :57                                         \n     mode            danceability      valence          energy     \n Length:953         Min.   :23.00   Min.   : 4.00   Min.   : 9.00  \n Class :character   1st Qu.:57.00   1st Qu.:32.00   1st Qu.:53.00  \n Mode  :character   Median :69.00   Median :51.00   Median :66.00  \n                    Mean   :66.97   Mean   :51.43   Mean   :64.28  \n                    3rd Qu.:78.00   3rd Qu.:70.00   3rd Qu.:77.00  \n                    Max.   :96.00   Max.   :97.00   Max.   :97.00  \n                                                                   \n  acousticness   instrumentalness    liveness      speechiness   \n Min.   : 0.00   Min.   : 0.000   Min.   : 3.00   Min.   : 2.00  \n 1st Qu.: 6.00   1st Qu.: 0.000   1st Qu.:10.00   1st Qu.: 4.00  \n Median :18.00   Median : 0.000   Median :12.00   Median : 6.00  \n Mean   :27.06   Mean   : 1.581   Mean   :18.21   Mean   :10.13  \n 3rd Qu.:43.00   3rd Qu.: 0.000   3rd Qu.:24.00   3rd Qu.:11.00  \n Max.   :97.00   Max.   :91.000   Max.   :97.00   Max.   :64.00  \n                                                                 \n      id           \n Length:953        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n```\n:::\n:::\n\n\n## Section 2.2 - Numerical and Visual Summary\n\nLet's split the dataset, explore more the data to do some wrangling and visualize some key variables in the dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# splitting dataset to have classifications to test. I will randomly split the dataset into 80% for training and 20% for testing\nset.seed(197)\nran <- sample(1:nrow(spotify), 0.8 * nrow(spotify)) \n\n\n# Split the data into training and testing sets\ntrain <- spotify[ran,]\ntest <- spotify[-ran,]\n```\n:::\n\n\nChecking the dimensions of the new datasets\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 762  25\n```\n:::\n\n```{.r .cell-code}\ndim(test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 191  25\n```\n:::\n:::\n\n\nTraining set has 762 rows/observations and 38 features or variables, while the test set contain 191 observations and the same 38 variables.\n\nI'll do some data wrangling for the train set\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Let's review the character variables and create dummies that can be use later when building the models\n\nunique(train$key)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"F#\" \"G\"  \"D\"  \"G#\" \"A#\" \"E\"  \"C#\" \"\"   \"A\"  \"D#\" \"F\"  \"B\" \n```\n:::\n\n```{.r .cell-code}\nunique(train$mode)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Minor\" \"Major\"\n```\n:::\n\n```{.r .cell-code}\n# Exploring the frequency of the values in the key\n\nkey.table<-table(train$key)\nkey.table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n    A A#  B C#  D D#  E  F F#  G G# \n74 61 43 65 94 62 28 51 69 64 82 69 \n```\n:::\n\n```{.r .cell-code}\n#replacing blank cells with NA\n\ntrain$key <- na_if(train$key, '')\n\n#replacing NA with the most frequent value in the feature, in this case C#\n\ntrain <- train %>% \n  mutate(key = ifelse(is.na(key), \"C#\", key))\n\n#I'll create dummy for key and mode \n\ntrain <- train %>% \n  mutate(mode.n = case_when(\n        mode == \"Major\" ~ 1,\n        mode == \"Minor\" ~ 0,\n        ))%>%\n  mutate(key.A = case_when(\n        key == \"A\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.B = case_when(\n        key == \"B\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.D = case_when(\n        key == \"D\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.E = case_when(\n        key == \"E\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.F = case_when(\n        key == \"F\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.G = case_when(\n        key == \"G\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.CS = case_when(\n        key == \"C#\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.FS = case_when(\n        key == \"F#\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.GS = case_when(\n        key == \"G#\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.AS = case_when(\n        key == \"A#\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.DS = case_when(\n        key == \"D#\" ~ 1,\n        TRUE ~ 0))\n\n#Lastly I'll replace the some NAs using median. For in_deezer_playlists, in_shazam_charts and stream\n\nmedian.stream.t <- median(train$streams, na.rm = TRUE)\nmedian.deezer.playlist.t <- median(train$in_deezer_playlists, na.rm = TRUE)\nmedian.shazam.chart.t <- median(train$in_shazam_charts, na.rm = TRUE)\n\ntrain <- train %>% mutate(streams = ifelse(is.na(streams), median.stream.t, streams)) %>%\n                   mutate(in_deezer_playlists = ifelse(is.na(in_deezer_playlists), median.deezer.playlist.t, in_deezer_playlists)) %>%\n                   mutate(in_shazam_charts = ifelse(is.na(in_shazam_charts), median.shazam.chart.t, in_shazam_charts))\n\nsummary(train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  track_name        artist.name        number.art.song released_year \n Length:762         Length:762         Min.   :1.000   Min.   :1930  \n Class :character   Class :character   1st Qu.:1.000   1st Qu.:2020  \n Mode  :character   Mode  :character   Median :1.000   Median :2022  \n                                       Mean   :1.539   Mean   :2018  \n                                       3rd Qu.:2.000   3rd Qu.:2022  \n                                       Max.   :8.000   Max.   :2023  \n released_month    released_day   in_spotify_playlists in_spotify_charts\n Min.   : 1.000   Min.   : 1.00   Min.   :   31.0      Min.   :  0.00   \n 1st Qu.: 3.000   1st Qu.: 6.00   1st Qu.:  853.8      1st Qu.:  0.00   \n Median : 5.000   Median :13.00   Median : 2167.0      Median :  3.00   \n Mean   : 6.004   Mean   :13.86   Mean   : 5188.8      Mean   : 11.86   \n 3rd Qu.: 9.000   3rd Qu.:22.00   3rd Qu.: 5412.0      3rd Qu.: 15.75   \n Max.   :12.000   Max.   :31.00   Max.   :52898.0      Max.   :147.00   \n    streams          in_apple_playlists in_apple_charts  in_deezer_playlists\n Min.   :2.762e+03   Min.   :  0.00     Min.   :  0.00   Min.   :  0.00     \n 1st Qu.:1.397e+08   1st Qu.: 13.00     1st Qu.:  7.00   1st Qu.: 13.00     \n Median :2.867e+08   Median : 34.50     Median : 38.00   Median : 35.00     \n Mean   :5.051e+08   Mean   : 66.10     Mean   : 52.61   Mean   : 97.88     \n 3rd Qu.:6.573e+08   3rd Qu.: 83.75     3rd Qu.: 87.00   3rd Qu.: 93.00     \n Max.   :3.563e+09   Max.   :537.00     Max.   :275.00   Max.   :974.00     \n in_deezer_charts in_shazam_charts      bpm             key           \n Min.   : 0.000   Min.   :  0.0    Min.   : 65.00   Length:762        \n 1st Qu.: 0.000   1st Qu.:  0.0    1st Qu.: 98.25   Class :character  \n Median : 0.000   Median :  2.0    Median :121.00   Mode  :character  \n Mean   : 2.554   Mean   : 50.1    Mean   :122.36                     \n 3rd Qu.: 2.000   3rd Qu.: 31.0    3rd Qu.:140.00                     \n Max.   :58.000   Max.   :953.0    Max.   :206.00                     \n     mode            danceability      valence          energy     \n Length:762         Min.   :23.00   Min.   : 4.00   Min.   : 9.00  \n Class :character   1st Qu.:57.00   1st Qu.:32.00   1st Qu.:54.00  \n Mode  :character   Median :69.00   Median :51.00   Median :66.00  \n                    Mean   :66.69   Mean   :51.50   Mean   :64.22  \n                    3rd Qu.:78.00   3rd Qu.:70.75   3rd Qu.:77.00  \n                    Max.   :95.00   Max.   :97.00   Max.   :97.00  \n  acousticness   instrumentalness    liveness      speechiness   \n Min.   : 0.00   Min.   : 0.000   Min.   : 3.00   Min.   : 2.00  \n 1st Qu.: 6.00   1st Qu.: 0.000   1st Qu.:10.00   1st Qu.: 4.00  \n Median :17.00   Median : 0.000   Median :12.00   Median : 6.00  \n Mean   :27.42   Mean   : 1.682   Mean   :18.12   Mean   :10.12  \n 3rd Qu.:44.00   3rd Qu.: 0.000   3rd Qu.:23.00   3rd Qu.:11.00  \n Max.   :97.00   Max.   :91.000   Max.   :91.00   Max.   :64.00  \n      id                mode.n          key.A             key.B       \n Length:762         Min.   :0.000   Min.   :0.00000   Min.   :0.0000  \n Class :character   1st Qu.:0.000   1st Qu.:0.00000   1st Qu.:0.0000  \n Mode  :character   Median :1.000   Median :0.00000   Median :0.0000  \n                    Mean   :0.584   Mean   :0.08005   Mean   :0.0853  \n                    3rd Qu.:1.000   3rd Qu.:0.00000   3rd Qu.:0.0000  \n                    Max.   :1.000   Max.   :1.00000   Max.   :1.0000  \n     key.D             key.E             key.F             key.G       \n Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.00000   Median :0.00000   Median :0.00000   Median :0.0000  \n Mean   :0.08136   Mean   :0.06693   Mean   :0.09055   Mean   :0.1076  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.0000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.00000   Max.   :1.0000  \n     key.CS           key.FS            key.GS            key.AS       \n Min.   :0.0000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :0.0000   Median :0.00000   Median :0.00000   Median :0.00000  \n Mean   :0.2205   Mean   :0.08399   Mean   :0.09055   Mean   :0.05643  \n 3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :1.0000   Max.   :1.00000   Max.   :1.00000   Max.   :1.00000  \n     key.DS       \n Min.   :0.00000  \n 1st Qu.:0.00000  \n Median :0.00000  \n Mean   :0.03675  \n 3rd Qu.:0.00000  \n Max.   :1.00000  \n```\n:::\n\n```{.r .cell-code}\ndim(train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 762  37\n```\n:::\n:::\n\n\nNow let's explore the training dataset with focus on Streams which is the target variable\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Let's see a summary of the target variable (number of streams)\n\nsummary.stream <- descr(train$streams)\nprint(summary.stream)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDescriptive Statistics  \ntrain$streams  \nN: 762  \n\n                          streams\n----------------- ---------------\n             Mean    505056426.77\n          Std.Dev    555606450.79\n              Min         2762.00\n               Q1    139681964.00\n           Median    286739476.00\n               Q3    657723613.00\n              Max   3562543890.00\n              MAD    275729763.36\n              IQR    517575700.75\n               CV            1.10\n         Skewness            1.98\n      SE.Skewness            0.09\n         Kurtosis            4.12\n          N.Valid          762.00\n        Pct.Valid          100.00\n```\n:::\n:::\n\n\nGiven the difference between Mean and Median (\\~2x) and curtosis value (\\>0 - 4.12), it sounds like a distribution far to a normal distribution with high probability of extreme values.\n\nLet's visualize the distribution. I'll use a density plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Density estimation\ndensity_streams <- density(train$streams)\ndensity_spot_play <- density(train$in_spotify_playlists)\ndensity_app_play <- density(train$in_apple_playlists)\ndensity_dee_play <- density(train$in_deezer_playlists)\ndensity_acc <- density(train$acousticness)\n\n# Plot the density curve\nplot(density_streams, type = \"l\", main = \"Density Plot for Streams\", xlab = \"Values\", ylab = \"Density\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(density_spot_play, type = \"l\", main = \"Density Plot for In Spotify Playlist\", xlab = \"Values\", ylab = \"Density\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(density_app_play, type = \"l\", main = \"Density Plot for In Apple Playlist\", xlab = \"Values\", ylab = \"Density\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(density_dee_play, type = \"l\", main = \"Density Plot for In Deezer Playlist\", xlab = \"Values\", ylab = \"Density\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-4.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(density_acc, type = \"l\", main = \"Density Plot for Acousticness\", xlab = \"Values\", ylab = \"Density\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-5.png){width=672}\n:::\n:::\n\n\nCertainly the distribution seems with a very heavy tail towards the higher values. Also looking at some key variables\n\nIt seems that just a few artist has a very high volume of streams represented by extreme values.\n\nJust curious about the streams by artist:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Let's create a table summarizing streams by artist\n\ndt.train <- data.table(train)\ndt.train2 <- dt.train[,list(Total.streams = sum(streams, na.rm=T), freq = .N), by = c(\"artist.name\")]\n\nStream_table <- dt.train2 %>% \n  group_by(artist.name) %>%\n  summarise(Total.streams = sum(Total.streams, na.rm=TRUE), Streams.Median = median(Total.streams, na.rm=TRUE))\nStream_table <- Stream_table %>%\n  mutate(Total.Streams.Percent = Total.streams/(sum(Total.streams))*100.2)\nStream_table <- Stream_table[with (Stream_table, order(-Total.Streams.Percent)),]\n\nStream_table <- Stream_table%>%\n  mutate(Cum_Percent = cumsum(Total.Streams.Percent))\n\ndata_subset <- slice(Stream_table, 1:30)\n\n# Print the subset of the data as a nice table using kable\nkable(data_subset)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> artist.name </th>\n   <th style=\"text-align:right;\"> Total.streams </th>\n   <th style=\"text-align:right;\"> Streams.Median </th>\n   <th style=\"text-align:right;\"> Total.Streams.Percent </th>\n   <th style=\"text-align:right;\"> Cum_Percent </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> EdSheeran </td>\n   <td style=\"text-align:right;\"> 12411186494 </td>\n   <td style=\"text-align:right;\"> 12411186494 </td>\n   <td style=\"text-align:right;\"> 3.2313660 </td>\n   <td style=\"text-align:right;\"> 3.231366 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TaylorSwift </td>\n   <td style=\"text-align:right;\"> 10812098960 </td>\n   <td style=\"text-align:right;\"> 10812098960 </td>\n   <td style=\"text-align:right;\"> 2.8150289 </td>\n   <td style=\"text-align:right;\"> 6.046395 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> HarryStyles </td>\n   <td style=\"text-align:right;\"> 9098362425 </td>\n   <td style=\"text-align:right;\"> 9098362425 </td>\n   <td style=\"text-align:right;\"> 2.3688419 </td>\n   <td style=\"text-align:right;\"> 8.415237 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TheWeeknd </td>\n   <td style=\"text-align:right;\"> 8957974292 </td>\n   <td style=\"text-align:right;\"> 8957974292 </td>\n   <td style=\"text-align:right;\"> 2.3322906 </td>\n   <td style=\"text-align:right;\"> 10.747527 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BadBunny </td>\n   <td style=\"text-align:right;\"> 5925299832 </td>\n   <td style=\"text-align:right;\"> 5925299832 </td>\n   <td style=\"text-align:right;\"> 1.5427060 </td>\n   <td style=\"text-align:right;\"> 12.290233 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> OliviaRodrigo </td>\n   <td style=\"text-align:right;\"> 4889343765 </td>\n   <td style=\"text-align:right;\"> 4889343765 </td>\n   <td style=\"text-align:right;\"> 1.2729854 </td>\n   <td style=\"text-align:right;\"> 13.563219 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ImagineDragons </td>\n   <td style=\"text-align:right;\"> 4434404750 </td>\n   <td style=\"text-align:right;\"> 4434404750 </td>\n   <td style=\"text-align:right;\"> 1.1545379 </td>\n   <td style=\"text-align:right;\"> 14.717757 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BrunoMars </td>\n   <td style=\"text-align:right;\"> 4185733280 </td>\n   <td style=\"text-align:right;\"> 4185733280 </td>\n   <td style=\"text-align:right;\"> 1.0897940 </td>\n   <td style=\"text-align:right;\"> 15.807551 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TheNeighbourhood </td>\n   <td style=\"text-align:right;\"> 4010009939 </td>\n   <td style=\"text-align:right;\"> 4010009939 </td>\n   <td style=\"text-align:right;\"> 1.0440428 </td>\n   <td style=\"text-align:right;\"> 16.851593 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ArcticMonkeys </td>\n   <td style=\"text-align:right;\"> 3781480286 </td>\n   <td style=\"text-align:right;\"> 3781480286 </td>\n   <td style=\"text-align:right;\"> 0.9845430 </td>\n   <td style=\"text-align:right;\"> 17.836136 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> DojaCat </td>\n   <td style=\"text-align:right;\"> 3659726247 </td>\n   <td style=\"text-align:right;\"> 3659726247 </td>\n   <td style=\"text-align:right;\"> 0.9528432 </td>\n   <td style=\"text-align:right;\"> 18.788980 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Eminem </td>\n   <td style=\"text-align:right;\"> 3254582526 </td>\n   <td style=\"text-align:right;\"> 3254582526 </td>\n   <td style=\"text-align:right;\"> 0.8473603 </td>\n   <td style=\"text-align:right;\"> 19.636340 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> DuaLipa </td>\n   <td style=\"text-align:right;\"> 3227639000 </td>\n   <td style=\"text-align:right;\"> 3227639000 </td>\n   <td style=\"text-align:right;\"> 0.8403454 </td>\n   <td style=\"text-align:right;\"> 20.476685 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LewisCapaldi </td>\n   <td style=\"text-align:right;\"> 3126653123 </td>\n   <td style=\"text-align:right;\"> 3126653123 </td>\n   <td style=\"text-align:right;\"> 0.8140528 </td>\n   <td style=\"text-align:right;\"> 21.290738 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> OneRepublic </td>\n   <td style=\"text-align:right;\"> 3097149603 </td>\n   <td style=\"text-align:right;\"> 3097149603 </td>\n   <td style=\"text-align:right;\"> 0.8063712 </td>\n   <td style=\"text-align:right;\"> 22.097109 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Adele </td>\n   <td style=\"text-align:right;\"> 3035946717 </td>\n   <td style=\"text-align:right;\"> 3035946717 </td>\n   <td style=\"text-align:right;\"> 0.7904365 </td>\n   <td style=\"text-align:right;\"> 22.887546 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> LinkinPark </td>\n   <td style=\"text-align:right;\"> 2985590613 </td>\n   <td style=\"text-align:right;\"> 2985590613 </td>\n   <td style=\"text-align:right;\"> 0.7773258 </td>\n   <td style=\"text-align:right;\"> 23.664872 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BTS </td>\n   <td style=\"text-align:right;\"> 2944237123 </td>\n   <td style=\"text-align:right;\"> 2944237123 </td>\n   <td style=\"text-align:right;\"> 0.7665591 </td>\n   <td style=\"text-align:right;\"> 24.431431 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TonesandI </td>\n   <td style=\"text-align:right;\"> 2864791672 </td>\n   <td style=\"text-align:right;\"> 2864791672 </td>\n   <td style=\"text-align:right;\"> 0.7458747 </td>\n   <td style=\"text-align:right;\"> 25.177306 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SZA </td>\n   <td style=\"text-align:right;\"> 2843515815 </td>\n   <td style=\"text-align:right;\"> 2843515815 </td>\n   <td style=\"text-align:right;\"> 0.7403354 </td>\n   <td style=\"text-align:right;\"> 25.917641 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> PostMaloneSwaeLee </td>\n   <td style=\"text-align:right;\"> 2808096550 </td>\n   <td style=\"text-align:right;\"> 2808096550 </td>\n   <td style=\"text-align:right;\"> 0.7311136 </td>\n   <td style=\"text-align:right;\"> 26.648755 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> JustinBieber </td>\n   <td style=\"text-align:right;\"> 2752482785 </td>\n   <td style=\"text-align:right;\"> 2752482785 </td>\n   <td style=\"text-align:right;\"> 0.7166341 </td>\n   <td style=\"text-align:right;\"> 27.365389 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> KendrickLamar </td>\n   <td style=\"text-align:right;\"> 2689179073 </td>\n   <td style=\"text-align:right;\"> 2689179073 </td>\n   <td style=\"text-align:right;\"> 0.7001524 </td>\n   <td style=\"text-align:right;\"> 28.065541 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> JamesArthur </td>\n   <td style=\"text-align:right;\"> 2686344050 </td>\n   <td style=\"text-align:right;\"> 2686344050 </td>\n   <td style=\"text-align:right;\"> 0.6994143 </td>\n   <td style=\"text-align:right;\"> 28.764955 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TheChainsmokersHalsey </td>\n   <td style=\"text-align:right;\"> 2591224264 </td>\n   <td style=\"text-align:right;\"> 2591224264 </td>\n   <td style=\"text-align:right;\"> 0.6746490 </td>\n   <td style=\"text-align:right;\"> 29.439604 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TheWeekndDaftPunk </td>\n   <td style=\"text-align:right;\"> 2565529693 </td>\n   <td style=\"text-align:right;\"> 2565529693 </td>\n   <td style=\"text-align:right;\"> 0.6679591 </td>\n   <td style=\"text-align:right;\"> 30.107563 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> GlassAnimals </td>\n   <td style=\"text-align:right;\"> 2557975762 </td>\n   <td style=\"text-align:right;\"> 2557975762 </td>\n   <td style=\"text-align:right;\"> 0.6659924 </td>\n   <td style=\"text-align:right;\"> 30.773556 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ShawnMendesCamilaCabello </td>\n   <td style=\"text-align:right;\"> 2484812918 </td>\n   <td style=\"text-align:right;\"> 2484812918 </td>\n   <td style=\"text-align:right;\"> 0.6469438 </td>\n   <td style=\"text-align:right;\"> 31.420500 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Mne </td>\n   <td style=\"text-align:right;\"> 2450538862 </td>\n   <td style=\"text-align:right;\"> 2450538862 </td>\n   <td style=\"text-align:right;\"> 0.6380202 </td>\n   <td style=\"text-align:right;\"> 32.058520 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Joji </td>\n   <td style=\"text-align:right;\"> 2357270185 </td>\n   <td style=\"text-align:right;\"> 2357270185 </td>\n   <td style=\"text-align:right;\"> 0.6137369 </td>\n   <td style=\"text-align:right;\"> 32.672257 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nIt is interesting to see that almost 10% of total streams are concentrated in 4 artist: Ed Sheeran, Tylor Swift, Harry Styles and The Weeknd. And 30% of all streams comes from 26 artists.\n\nIt is important to mention that here \"artist\" means unique artist or combination of artists per song, for example, if Taylor Swift has a song along with Ed Sheeran, then it will be considered a unique artist in the analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#how many unique artist are here\nn_distinct(train$artist.name)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 536\n```\n:::\n:::\n\n\nWe have 536 \"unique\" artist, so following previous observation we can say that 5% of the artist (26 artists) concentrate 30% of all streams.\n\nSomething that I think would be interesting is segmenting the data set in Deciles to create categories of artist from the highest to lowest streamer.\n\nThen we can use those categories as a classification target.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Let's create the Decile variable based on the streams to use it later in classification method\n\ntrain <- train %>% mutate(class.decile = ntile(streams, 10))\n```\n:::\n\n\nNow let's explore a few other features vs streams\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Box plot for Strems and Mode, Key and Number of Artists in the song\n\nbox1 <- ggplot(train, aes(x =mode, y = streams))+\n  geom_boxplot(alpha=0.7, outlier.shape = NA)+\n  facet_wrap(.~number.art.song, scales = \"free\")+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  theme(legend.position = \"right\") +\n  coord_cartesian(ylim =  c(1e+7, 1e+9))+\n  labs(title=\"Streams vs Mode\",\n       subtitle = \"Grouped by Number of Artist in the Song\",\n        x =\"Mode\", y = \"Streams\")\nbox1\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=1440}\n:::\n\n```{.r .cell-code}\nbox2 <- ggplot(train, aes(x =key, y = streams))+\n  geom_boxplot(alpha=0.7, outlier.shape = NA)+\n  facet_wrap(.~number.art.song, scales = \"free\")+\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))+\n  theme(legend.position = \"right\") +\n  coord_cartesian(ylim =  c(1e+7, 1.5e+9))+\n  labs(title=\"Streams vs Key\",\n       subtitle = \"Grouped by Number of Artist in the Song\",\n        x =\"Key\", y = \"Streams\")\nbox2\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-2.png){width=1440}\n:::\n:::\n\n\nIt is interesting to see that there is not too much variability when comparing streams by Mode and Number of Artist in the song, but when comparing among Keys seems that the variability increases when the song has 2 or 3 artists involved.\n\nLet's now look at numerical variables using correlation matrix and scatter plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#I'll create a dataset with only numeric variables, also I will exclude from here class.decile because is redundnat with streams\n\ntrain.n <- train %>% select(-track_name, -artist.name, -key, -mode, -id, -class.decile)\n\n# Cor Matrix\ncor_matrix1 <- cor(train.n)\ncor_matrix1 <- round(cor_matrix1, 2)\n\n# Let's see a color matrix to simplify visualization\n\ncorrplot(cor_matrix1, method = \"circle\", tl.cex = 0.5)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nI can see that there is correlation among presence in charts and playlists among the different platforms, in particular seems there is a strong correlation between Spotify and Apple Music playlists and among the charts in all platforms. Here could be some milticolinearity that I may need to pay attention.\n\nOn the other hand there seems also some multicolinearity among song characteristics (danceability, energy, valence, acousticness, instrumentalness, liveness, speachness), but none of them seems highly correlated to streams. Also noted strong inverse correlation between acousticness and energy).\n\nLastly, seems that number of streams is highly and positive correlated to the number of playlists the song is included in any of the platforms (spotify, apple and deezer).\n\nLet's visualize Streams and playlists in scatter plots\n\n\n::: {.cell}\n\n```{.r .cell-code}\nscatter1 <- ggplot(train, aes(in_deezer_playlists,streams))+\n  geom_point()+\n  scale_y_continuous(limits=c(1e+8,1.5e+9))+\n  labs(title=\"Scatter Plot - Streams vs Deezer playlist precense\",\n        x =\"In Deezer Playlist\", y = \"Streams\")\nscatter1\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 175 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\nscatter2 <- ggplot(train, aes(in_apple_playlists,streams))+\n  geom_point()+\n  scale_y_continuous(limits=c(1e+8,1.5e+9))+\n  labs(title=\"Scatter Plot - Streams vs Apple playlist precense\",\n        x =\"In Apple Music Playlist\", y = \"Streams\")\nscatter2\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 175 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-2.png){width=672}\n:::\n\n```{.r .cell-code}\nscatter3 <- ggplot(train, aes(in_spotify_playlists,streams))+\n  geom_point()+\n  scale_y_continuous(limits=c(1e+8,1.5e+9))+\n  labs(title=\"Scatter Plot - Streams vs Spotify playlist precense\",\n        x =\"In Spotify Playlist\", y = \"Streams\")\nscatter3\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 175 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-3.png){width=672}\n:::\n:::\n\n\n# Section 3 - Evaluation Metric\n\nI'll focus on Regression method for modeling. I have 32 features in my training set including the numerical variables only, and since it can't be considered a large number of features so I'll pass on any shrinking method this time (like PCA).\n\nGiven the distribution of the target variable (streams) is very skewed and I won't transform the variable (i.e log), I rather use a metric less sensitive to outliners. So I'll use **Median Absolute Error** (mdae in R).\n\n# Section 4 - Fit models\n\nI'll use linear regression, lasso regression and random forest\n\n## Section 4.1 - Data preprocessing\n\n### Method 1 - Linear Regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Linear regression with all features\nmodel1 <- lm(streams ~ ., data = train.n)\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = streams ~ ., data = train.n)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-1.467e+09 -1.336e+08 -3.137e+07  9.722e+07  2.190e+09 \n\nCoefficients: (1 not defined because of singularities)\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          -8.558e+09  2.096e+09  -4.083 4.94e-05 ***\nnumber.art.song      -3.182e+07  1.279e+07  -2.487  0.01311 *  \nreleased_year         4.334e+06  1.039e+06   4.170 3.42e-05 ***\nreleased_month        2.940e+06  3.022e+06   0.973  0.33095    \nreleased_day          3.147e+06  1.153e+06   2.730  0.00648 ** \nin_spotify_playlists  3.793e+04  2.047e+03  18.530  < 2e-16 ***\nin_spotify_charts     4.781e+06  7.712e+05   6.200 9.45e-10 ***\nin_apple_playlists    2.384e+06  2.048e+05  11.640  < 2e-16 ***\nin_apple_charts      -2.736e+05  2.625e+05  -1.042  0.29755    \nin_deezer_playlists   4.687e+05  7.101e+04   6.600 7.88e-11 ***\nin_deezer_charts     -8.956e+06  2.387e+06  -3.752  0.00019 ***\nin_shazam_charts     -4.752e+05  9.508e+04  -4.998 7.25e-07 ***\nbpm                   1.812e+04  3.808e+05   0.048  0.96206    \ndanceability          3.906e+05  8.622e+05   0.453  0.65064    \nvalence              -6.102e+05  5.438e+05  -1.122  0.26225    \nenergy               -7.588e+05  8.644e+05  -0.878  0.38032    \nacousticness          9.046e+05  5.141e+05   1.760  0.07890 .  \ninstrumentalness     -1.709e+06  1.188e+06  -1.438  0.15076    \nliveness             -1.696e+05  7.826e+05  -0.217  0.82847    \nspeechiness          -1.247e+06  1.086e+06  -1.149  0.25107    \nmode.n                4.972e+06  2.275e+07   0.219  0.82710    \nkey.A                 1.095e+07  6.603e+07   0.166  0.86837    \nkey.B                -6.133e+07  6.561e+07  -0.935  0.35027    \nkey.D                -7.028e+07  6.661e+07  -1.055  0.29171    \nkey.E                -5.650e+06  6.776e+07  -0.083  0.93357    \nkey.F                -4.791e+07  6.494e+07  -0.738  0.46090    \nkey.G                -8.322e+07  6.341e+07  -1.312  0.18977    \nkey.CS               -7.180e+07  5.961e+07  -1.204  0.22881    \nkey.FS               -9.925e+07  6.553e+07  -1.515  0.13031    \nkey.GS               -3.300e+07  6.500e+07  -0.508  0.61177    \nkey.AS                3.077e+07  7.020e+07   0.438  0.66133    \nkey.DS                       NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 284800000 on 731 degrees of freedom\nMultiple R-squared:  0.7477,\tAdjusted R-squared:  0.7373 \nF-statistic: 72.21 on 30 and 731 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nOut of the 31 features only 10 show a significant relationship with the number of streams, most of them around presence in playlists or charts in the different platforms, only one is related to the music compositions (acousticness).\n\nI'll try other liner models:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#I'll log the target to see if the prediction improves\nmodel2 <- lm(log(streams) ~ number.art.song + released_year + released_day + in_spotify_playlists + in_spotify_charts + in_apple_playlists + in_deezer_playlists + in_deezer_charts + in_shazam_charts + acousticness, data = train.n)\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = log(streams) ~ number.art.song + released_year + \n    released_day + in_spotify_playlists + in_spotify_charts + \n    in_apple_playlists + in_deezer_playlists + in_deezer_charts + \n    in_shazam_charts + acousticness, data = train.n)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.9204  -0.4216   0.0697   0.5158   2.0350 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           1.820e+01  5.802e+00   3.138  0.00177 ** \nnumber.art.song      -8.926e-02  3.492e-02  -2.556  0.01078 *  \nreleased_year         3.179e-04  2.872e-03   0.111  0.91191    \nreleased_day          8.862e-03  3.253e-03   2.724  0.00660 ** \nin_spotify_playlists  5.709e-05  5.663e-06  10.081  < 2e-16 ***\nin_spotify_charts     2.409e-03  1.998e-03   1.205  0.22841    \nin_apple_playlists    3.415e-03  5.457e-04   6.259 6.51e-10 ***\nin_deezer_playlists   1.585e-03  2.002e-04   7.918 8.66e-15 ***\nin_deezer_charts     -9.397e-03  6.756e-03  -1.391  0.16467    \nin_shazam_charts     -4.756e-04  2.626e-04  -1.811  0.07052 .  \nacousticness          1.387e-04  1.142e-03   0.121  0.90340    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8143 on 751 degrees of freedom\nMultiple R-squared:  0.5021,\tAdjusted R-squared:  0.4955 \nF-statistic: 75.75 on 10 and 751 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nActually the model deteriorates significantly when logging streams variable (Adjusted R2=.5 vs .73 with model 1).\n\nA third model keeping only significant features founded in model 1:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Let's keep only the significant features\n\nmodel3 <- lm(streams ~ number.art.song + released_year + released_day + in_spotify_playlists + in_spotify_charts + in_apple_playlists + in_deezer_playlists + in_deezer_charts + in_shazam_charts + acousticness, data = train.n)\nsummary(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = streams ~ number.art.song + released_year + released_day + \n    in_spotify_playlists + in_spotify_charts + in_apple_playlists + \n    in_deezer_playlists + in_deezer_charts + in_shazam_charts + \n    acousticness, data = train.n)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-1.520e+09 -1.330e+08 -3.618e+07  9.146e+07  2.143e+09 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)          -9.335e+09  2.032e+09  -4.595 5.08e-06 ***\nnumber.art.song      -3.621e+07  1.223e+07  -2.961 0.003159 ** \nreleased_year         4.670e+06  1.006e+06   4.643 4.06e-06 ***\nreleased_day          2.793e+06  1.139e+06   2.452 0.014437 *  \nin_spotify_playlists  3.770e+04  1.983e+03  19.011  < 2e-16 ***\nin_spotify_charts     4.274e+06  6.997e+05   6.108 1.61e-09 ***\nin_apple_playlists    2.357e+06  1.911e+05  12.334  < 2e-16 ***\nin_deezer_playlists   4.690e+05  7.009e+04   6.691 4.33e-11 ***\nin_deezer_charts     -9.241e+06  2.366e+06  -3.906 0.000102 ***\nin_shazam_charts     -4.775e+05  9.195e+04  -5.193 2.67e-07 ***\nacousticness          1.199e+06  4.000e+05   2.996 0.002823 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 285100000 on 751 degrees of freedom\nMultiple R-squared:  0.7401,\tAdjusted R-squared:  0.7366 \nF-statistic: 213.8 on 10 and 751 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nThe power of explanation when pulling out non-relevant features (based on the statistical significance) practically does not change.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make predictions for new data\npredicted_1 <- predict(model1, train.n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in predict.lm(model1, train.n): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\n```\n:::\n\n```{.r .cell-code}\npredicted_2 <- predict(model2, train.n)\npredicted_3 <- predict(model3, train.n)\n\n#MdAE      \n\nmdae_lm1 <- mdae(train.n$streams, predicted_1)\nmdae_lm2 <- mdae(train.n$streams, predicted_2)\nmdae_lm3 <- mdae(train.n$streams, predicted_3)\n\nprint(mdae_lm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 119534826\n```\n:::\n\n```{.r .cell-code}\nprint(mdae_lm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 286739457\n```\n:::\n\n```{.r .cell-code}\nprint(mdae_lm3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 116079107\n```\n:::\n:::\n\n\nSeems that model 3 is the best option based on the Median Absolute Error value (lowest error). Logging streams makes the model worst, and interesting to see that model 1 which includes all variables and has the highest R2 has a higher error than model 3 which includes only the most relevant features based on the p value significance.\n\n### Method 2 - Lasso Regression\n\nLasso is particularly useful in situations where feature selection is desired or when the dataset contains many irrelevant or redundant predictors, which seems this case. Also select the most relevant features and reduce coefficient of irrelevant features, which at the same time allows to handle multicollinearity among predictor variables which also seems appropriate given the strong correlation among playlist and chart variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(train.n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n number.art.song released_year  released_month    released_day  \n Min.   :1.000   Min.   :1930   Min.   : 1.000   Min.   : 1.00  \n 1st Qu.:1.000   1st Qu.:2020   1st Qu.: 3.000   1st Qu.: 6.00  \n Median :1.000   Median :2022   Median : 5.000   Median :13.00  \n Mean   :1.539   Mean   :2018   Mean   : 6.004   Mean   :13.86  \n 3rd Qu.:2.000   3rd Qu.:2022   3rd Qu.: 9.000   3rd Qu.:22.00  \n Max.   :8.000   Max.   :2023   Max.   :12.000   Max.   :31.00  \n in_spotify_playlists in_spotify_charts    streams          in_apple_playlists\n Min.   :   31.0      Min.   :  0.00    Min.   :2.762e+03   Min.   :  0.00    \n 1st Qu.:  853.8      1st Qu.:  0.00    1st Qu.:1.397e+08   1st Qu.: 13.00    \n Median : 2167.0      Median :  3.00    Median :2.867e+08   Median : 34.50    \n Mean   : 5188.8      Mean   : 11.86    Mean   :5.051e+08   Mean   : 66.10    \n 3rd Qu.: 5412.0      3rd Qu.: 15.75    3rd Qu.:6.573e+08   3rd Qu.: 83.75    \n Max.   :52898.0      Max.   :147.00    Max.   :3.563e+09   Max.   :537.00    \n in_apple_charts  in_deezer_playlists in_deezer_charts in_shazam_charts\n Min.   :  0.00   Min.   :  0.00      Min.   : 0.000   Min.   :  0.0   \n 1st Qu.:  7.00   1st Qu.: 13.00      1st Qu.: 0.000   1st Qu.:  0.0   \n Median : 38.00   Median : 35.00      Median : 0.000   Median :  2.0   \n Mean   : 52.61   Mean   : 97.88      Mean   : 2.554   Mean   : 50.1   \n 3rd Qu.: 87.00   3rd Qu.: 93.00      3rd Qu.: 2.000   3rd Qu.: 31.0   \n Max.   :275.00   Max.   :974.00      Max.   :58.000   Max.   :953.0   \n      bpm          danceability      valence          energy     \n Min.   : 65.00   Min.   :23.00   Min.   : 4.00   Min.   : 9.00  \n 1st Qu.: 98.25   1st Qu.:57.00   1st Qu.:32.00   1st Qu.:54.00  \n Median :121.00   Median :69.00   Median :51.00   Median :66.00  \n Mean   :122.36   Mean   :66.69   Mean   :51.50   Mean   :64.22  \n 3rd Qu.:140.00   3rd Qu.:78.00   3rd Qu.:70.75   3rd Qu.:77.00  \n Max.   :206.00   Max.   :95.00   Max.   :97.00   Max.   :97.00  \n  acousticness   instrumentalness    liveness      speechiness   \n Min.   : 0.00   Min.   : 0.000   Min.   : 3.00   Min.   : 2.00  \n 1st Qu.: 6.00   1st Qu.: 0.000   1st Qu.:10.00   1st Qu.: 4.00  \n Median :17.00   Median : 0.000   Median :12.00   Median : 6.00  \n Mean   :27.42   Mean   : 1.682   Mean   :18.12   Mean   :10.12  \n 3rd Qu.:44.00   3rd Qu.: 0.000   3rd Qu.:23.00   3rd Qu.:11.00  \n Max.   :97.00   Max.   :91.000   Max.   :91.00   Max.   :64.00  \n     mode.n          key.A             key.B            key.D        \n Min.   :0.000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :1.000   Median :0.00000   Median :0.0000   Median :0.00000  \n Mean   :0.584   Mean   :0.08005   Mean   :0.0853   Mean   :0.08136  \n 3rd Qu.:1.000   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.00000  \n Max.   :1.000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000  \n     key.E             key.F             key.G            key.CS      \n Min.   :0.00000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.00000   Median :0.00000   Median :0.0000   Median :0.0000  \n Mean   :0.06693   Mean   :0.09055   Mean   :0.1076   Mean   :0.2205  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.0000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000  \n     key.FS            key.GS            key.AS            key.DS       \n Min.   :0.00000   Min.   :0.00000   Min.   :0.00000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.00000  \n Median :0.00000   Median :0.00000   Median :0.00000   Median :0.00000  \n Mean   :0.08399   Mean   :0.09055   Mean   :0.05643   Mean   :0.03675  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.00000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.00000   Max.   :1.00000  \n```\n:::\n\n```{.r .cell-code}\n#this time I'll separate target variable on a different object because I feel will be easier to handle\n\nstream.train <- train.n$streams\n\n#Now will exclude streams from the dataset and predicted values from linear regression\n\ntrain.n2 <- train.n %>% select(-streams)\n\n#I'll scale train features\n\nxtrain.n2.scaled <- scale(train.n2)\n\n#I'll scale also streams just to used in the cross validation. I rather use scaling as it keeps the distribution\n\ny.train.n2.scaled <- scale(stream.train)\n\n#I'll create the lambda sequence value \n\nlambda.array <- seq(from=0.1, to= 100, by=0.1)\n\n#Cross validation using cv.glmnet\n\ncv.lasso.model <- cv.glmnet(xtrain.n2.scaled, y.train.n2.scaled, alpha=1, lambda=lambda.array)\n\nplot(cv.lasso.model, xvar = 'lambda')\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in plot.window(...): \"xvar\" is not a graphical parameter\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in plot.xy(xy, type, ...): \"xvar\" is not a graphical parameter\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in axis(side = side, at = at, labels = labels, ...): \"xvar\" is not a\ngraphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"xvar\" is not a\ngraphical parameter\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in box(...): \"xvar\" is not a graphical parameter\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in title(...): \"xvar\" is not a graphical parameter\n```\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#getting the best lambda\n\nbest.lasso.lambda <- cv.lasso.model$lambda.min\nbest.lasso.lambda\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1\n```\n:::\n\n```{.r .cell-code}\n#MSE\nmean.lasso.error <- mean(cv.lasso.model$cvm)\nprint(mean.lasso.error)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9984841\n```\n:::\n\n```{.r .cell-code}\nprint(coef(cv.lasso.model))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n32 x 1 sparse Matrix of class \"dgCMatrix\"\n                               s1\n(Intercept)          3.050052e-17\nnumber.art.song      .           \nreleased_year        .           \nreleased_month       .           \nreleased_day         .           \nin_spotify_playlists 4.395318e-01\nin_spotify_charts    .           \nin_apple_playlists   3.224483e-01\nin_apple_charts      .           \nin_deezer_playlists  5.549454e-02\nin_deezer_charts     .           \nin_shazam_charts     .           \nbpm                  .           \ndanceability         .           \nvalence              .           \nenergy               .           \nacousticness         .           \ninstrumentalness     .           \nliveness             .           \nspeechiness          .           \nmode.n               .           \nkey.A                .           \nkey.B                .           \nkey.D                .           \nkey.E                .           \nkey.F                .           \nkey.G                .           \nkey.CS               .           \nkey.FS               .           \nkey.GS               .           \nkey.AS               .           \nkey.DS               .           \n```\n:::\n:::\n\n\nInteresting to see that Lasso model keeps the presence of the song in playlist on the 3 main streaming platforms.\n\n### Method 3 - Random Forest\n\nLastly, I'll use random forest and this time I'll use the class.deciles created previously to use it as classification.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#First I'll bring back as a separate object the class.deciles variable\n\ntrain.n2$class.decile <- train$class.decile\ntrain.n2$class.decile <- as.factor(train.n2$class.decile)\n```\n:::\n\n\nTune the hyperparameters:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec <- rand_forest(trees = tune(), mtry = tune()) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\")\n\n#starting with this values\n\nrf_grid <- grid_regular(\n  trees(range = c(100, 800)),\n  mtry(range = c(2, 31)),\n  levels = 5)\n\nset.seed(1977)\nfolds <- vfold_cv(train.n2, v = 5)\n\nrf_wf <- workflow() %>%\n  add_model(tune_spec) %>%\n  add_formula(class.decile ~ .)\n\n#For the purpose to train the model I'll use F1 as metric, despite I'll use mdae for measuring performance later\n\nmy_metrics <- metric_set(f_meas)\n\nrf_res <- \n  rf_wf %>% \n  tune_grid(resamples = folds, grid = rf_grid, metrics = my_metrics)\n```\n:::\n\n\nVisualize the results and best parameters:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_res %>%\n  collect_metrics() %>%\n  filter(.metric == \"f_meas\") %>%\n  select(mtry, trees, mean) %>%\n  ggplot(aes(mtry, trees, fill = mean)) +\n    geom_tile() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nBest Parameters:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_params <- rf_res %>%\n  select_best(\"f_meas\")\n\nbest_params\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1  3\n   mtry trees .config              \n  <int> <int> <chr>                \n1    31   275 Preprocessor1_Model22\n```\n:::\n:::\n\n\nExplore a different region\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Now with this values\n\nrf_grid2 <- grid_regular(\n  trees(range = c(100, 500)),\n  mtry(range = c(10, 31)),\n  levels = 5)\n\nset.seed(1979)\nfolds2 <- vfold_cv(train.n2, v = 10)\n\nrf_res2 <- \n  rf_wf %>% \n  tune_grid(resamples = folds2, grid = rf_grid2, metrics = my_metrics)\n\nrf_res2 %>%\n  collect_metrics() %>%\n  filter(.metric == \"f_meas\") %>%\n  select(mtry, trees, mean) %>%\n  ggplot(aes(mtry, trees, fill = mean)) +\n    geom_tile() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbest_params2 <- rf_res2 %>%\n  select_best(\"f_meas\")\n\nbest_params2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1  3\n   mtry trees .config              \n  <int> <int> <chr>                \n1    10   300 Preprocessor1_Model03\n```\n:::\n:::\n\n\n## Section 4.2 - Choose hyperparameters; fit and test models\n\nFirst I'll make adjustments as training set, to the test set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  track_name        artist.name        number.art.song released_year \n Length:191         Length:191         Min.   :1.000   Min.   :1957  \n Class :character   Class :character   1st Qu.:1.000   1st Qu.:2020  \n Mode  :character   Mode  :character   Median :1.000   Median :2022  \n                                       Mean   :1.623   Mean   :2019  \n                                       3rd Qu.:2.000   3rd Qu.:2022  \n                                       Max.   :7.000   Max.   :2023  \n                                                                     \n released_month    released_day   in_spotify_playlists in_spotify_charts\n Min.   : 1.000   Min.   : 1.00   Min.   :   86        Min.   : 0.00    \n 1st Qu.: 3.000   1st Qu.: 6.00   1st Qu.: 1006        1st Qu.: 0.00    \n Median : 6.000   Median :14.00   Median : 2415        Median : 4.00    \n Mean   : 6.152   Mean   :14.22   Mean   : 5245        Mean   :12.59    \n 3rd Qu.: 9.000   3rd Qu.:22.00   3rd Qu.: 5868        3rd Qu.:20.00    \n Max.   :12.000   Max.   :31.00   Max.   :43899        Max.   :83.00    \n                                                                        \n    streams          in_apple_playlists in_apple_charts  in_deezer_playlists\n Min.   :1.365e+06   Min.   :  0.00     Min.   :  0.00   Min.   :  0.0      \n 1st Qu.:1.509e+08   1st Qu.: 13.00     1st Qu.:  8.00   1st Qu.: 14.0      \n Median :3.041e+08   Median : 32.00     Median : 39.00   Median : 39.0      \n Mean   :5.492e+08   Mean   : 74.66     Mean   : 49.09   Mean   :132.8      \n 3rd Qu.:7.416e+08   3rd Qu.:107.00     3rd Qu.: 81.50   3rd Qu.:150.8      \n Max.   :3.704e+09   Max.   :672.00     Max.   :199.00   Max.   :965.0      \n                                                         NA's   :13         \n in_deezer_charts in_shazam_charts      bpm            key           \n Min.   : 0.000   Min.   :  0.00   Min.   : 71.0   Length:191        \n 1st Qu.: 0.000   1st Qu.:  0.00   1st Qu.:101.5   Class :character  \n Median : 0.000   Median :  3.00   Median :120.0   Mode  :character  \n Mean   : 3.115   Mean   : 43.64   Mean   :123.2                     \n 3rd Qu.: 2.000   3rd Qu.: 34.75   3rd Qu.:141.0                     \n Max.   :45.000   Max.   :727.00   Max.   :206.0                     \n                  NA's   :13                                         \n     mode            danceability     valence          energy     \n Length:191         Min.   :25.0   Min.   : 4.00   Min.   :20.00  \n Class :character   1st Qu.:58.0   1st Qu.:35.00   1st Qu.:52.50  \n Mode  :character   Median :70.0   Median :52.00   Median :66.00  \n                    Mean   :68.1   Mean   :51.15   Mean   :64.51  \n                    3rd Qu.:79.0   3rd Qu.:68.00   3rd Qu.:76.50  \n                    Max.   :96.0   Max.   :97.00   Max.   :97.00  \n                                                                  \n  acousticness   instrumentalness    liveness      speechiness   \n Min.   : 0.00   Min.   : 0.000   Min.   : 3.00   Min.   : 2.00  \n 1st Qu.: 6.00   1st Qu.: 0.000   1st Qu.:10.00   1st Qu.: 4.00  \n Median :18.00   Median : 0.000   Median :13.00   Median : 6.00  \n Mean   :25.62   Mean   : 1.178   Mean   :18.59   Mean   :10.19  \n 3rd Qu.:38.50   3rd Qu.: 0.000   3rd Qu.:25.50   3rd Qu.:13.50  \n Max.   :94.00   Max.   :51.000   Max.   :97.00   Max.   :45.00  \n                                                                 \n      id           \n Length:191        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n```\n:::\n\n```{.r .cell-code}\n# Let's review the character variables and create dummies that can be use later when building the models\n\nunique(test$key)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"F\"  \"G#\" \"B\"  \"D\"  \"G\"  \"A#\" \"E\"  \"C#\" \"\"   \"F#\" \"A\"  \"D#\"\n```\n:::\n\n```{.r .cell-code}\nunique(test$mode)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Major\" \"Minor\"\n```\n:::\n\n```{.r .cell-code}\n# Exploring the frequency of the values in the key\n\nkey.table<-table(test$key)\nkey.table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n    A A#  B C#  D D#  E  F F#  G G# \n21 14 14 16 26 19  5 11 20  9 14 22 \n```\n:::\n\n```{.r .cell-code}\n#replacing blank cells with NA\n\ntest$key <- na_if(test$key, '')\n\n#replacing NA with the most frequent value in the feature, in this case C#\n\ntest <- test %>% \n  mutate(key = ifelse(is.na(key), \"C#\", key))\n\n#I'll create dummy for key and mode \n\ntest <- test %>% \n  mutate(mode.n = case_when(\n        mode == \"Major\" ~ 1,\n        mode == \"Minor\" ~ 0,\n        ))%>%\n  mutate(key.A = case_when(\n        key == \"A\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.B = case_when(\n        key == \"B\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.D = case_when(\n        key == \"D\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.E = case_when(\n        key == \"E\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.F = case_when(\n        key == \"F\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.G = case_when(\n        key == \"G\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.CS = case_when(\n        key == \"C#\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.FS = case_when(\n        key == \"F#\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.GS = case_when(\n        key == \"G#\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.AS = case_when(\n        key == \"A#\" ~ 1,\n        TRUE ~ 0))%>%\n  mutate(key.DS = case_when(\n        key == \"D#\" ~ 1,\n        TRUE ~ 0))\n\n#Lastly I'll replace the some NAs using median. For in_deezer_playlists, in_shazam_charts and stream\n\nmedian.deezer.playlist.ts <- median(test$in_deezer_playlists, na.rm = TRUE)\nmedian.shazam.chart.ts <- median(test$in_shazam_charts, na.rm = TRUE)\n\ntest <- test %>% \n  mutate(in_deezer_playlists = ifelse(is.na(in_deezer_playlists), median.deezer.playlist.t, in_deezer_playlists)) %>%\n  mutate(in_shazam_charts = ifelse(is.na(in_shazam_charts), median.shazam.chart.t, in_shazam_charts))\n\n#Let's create the Decile variable based on the streams to use it later in classification method\n\ntest <- test %>% mutate(class.decile = ntile(streams, 10))\n\n#now the dataset for testing, removing non-numeric or irrelevant variables\n\ntest.n <- test %>% select(-track_name, -artist.name, -key, -mode, -id, -class.decile)\n\n#extracting test actual streams \n\nstream.test <- test.n$streams\n```\n:::\n\n\n### Linear regression fitting and testing\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make predictions for new data\nlm.predicted.1 <- predict(model1, test.n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in predict.lm(model1, test.n): prediction from rank-deficient fit;\nattr(*, \"non-estim\") has doubtful cases\n```\n:::\n\n```{.r .cell-code}\nlm.predicted.3 <- predict(model3, test.n)\n\n#Checking MdAE\nmdae_lm1.final <- mdae(stream.test, lm.predicted.1)\nprint(mdae_lm1.final)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 135837770\n```\n:::\n\n```{.r .cell-code}\nmdae_lm3.final <- mdae(stream.test, lm.predicted.3)\nprint(mdae_lm3.final)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 123474556\n```\n:::\n:::\n\n\n### Lasso Regression fitting and testing\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Now will exclude streams from the dataset and predicted values from linear regression\n\ntest.n2 <- test.n %>% select(-streams)\n\n#I'll scale test features\n\nxtest.n2.scaled <- scale(test.n2)\n\n#fit the model using the best lambda in lasso\n\nlasso.model <- glmnet(xtest.n2.scaled, stream.test, alpha=1, lambda=best.lasso.lambda)\n coef(lasso.model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n32 x 1 sparse Matrix of class \"dgCMatrix\"\n                             s0\n(Intercept)           549175763\nnumber.art.song       -14064461\nreleased_year         -28898388\nreleased_month         15279704\nreleased_day           11015034\nin_spotify_playlists  226034156\nin_spotify_charts     151290594\nin_apple_playlists    249601103\nin_apple_charts        21338444\nin_deezer_playlists   114996405\nin_deezer_charts      -69063564\nin_shazam_charts     -126032019\nbpm                    -3506104\ndanceability          -47405242\nvalence                -7346601\nenergy                -18401617\nacousticness          -17181614\ninstrumentalness        7630502\nliveness               14395334\nspeechiness            -4810544\nmode.n                -13167404\nkey.A                 -12077321\nkey.B                   5200964\nkey.D                   5981359\nkey.E                   6473279\nkey.F                  17801687\nkey.G                 -21177792\nkey.CS                 -4135984\nkey.FS                 24496493\nkey.GS                -19115050\nkey.AS                  1662262\nkey.DS                 11780702\n```\n:::\n\n```{.r .cell-code}\n#Predict streams in test set\n\nytest.lasso.pred <- predict(lasso.model, newx = xtest.n2.scaled, penalty = best.lasso.lambda)\n\n\n#Checking MdAE\nmdae_lasso.final <- mdae(stream.test, ytest.lasso.pred)\nprint(mdae_lasso.final)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 113556904\n```\n:::\n:::\n\n\n### Random Forest fitting and testing\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#First I need to bring back class.decile for the test set\n\ntest.n2$class.decile <- test$class.decile\ntest.n2$class.decile <- as.factor(test.n2$class.decile)\ntest.class <- test.n2$class.decile\n```\n:::\n\n\nWill first check model 1 (mtry=31 and trees=275)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#fit the model 1\n\nrf1 <- rand_forest(mtry=31, trees=275) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\")\n\n\nrf_fit1 <- rf1 %>%\n  fit(class.decile ~ ., data = test.n2)\n\n#Predict on the test set using first parameters:\n\ntest_pred1 <-  rf_fit1 %>%\n  predict(test.n2) %>%\n  bind_cols(test.n2) %>%\n  select(class.decile, .pred_class)\n\ntest_pred1 %>%\n    my_metrics(truth = class.decile, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1  3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 f_meas  macro          0.995\n```\n:::\n\n```{.r .cell-code}\n#Transforming to numeric to be able to calculate mdae\n\nrf1.pred <- test_pred1$.pred_class\nrf1.pred <- as.numeric(rf1.pred)\ntest.class.n <- as.numeric(test.class)\n\n#Let's see the consufion matrix\nconfusion_matrix1 <- table(test.class.n, rf1.pred)\nconfusion_matrix1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            rf1.pred\ntest.class.n  1  2  3  4  5  6  7  8  9 10\n          1  20  0  0  0  0  0  0  0  0  0\n          2   0 19  0  0  0  0  0  0  0  0\n          3   0  0 19  0  0  0  0  0  0  0\n          4   0  0  0 19  0  0  0  0  0  0\n          5   0  0  0  0 18  0  0  0  1  0\n          6   0  0  0  0  0 19  0  0  0  0\n          7   0  0  0  0  0  0 19  0  0  0\n          8   0  0  0  0  0  0  0 19  0  0\n          9   0  0  0  0  0  0  0  0 19  0\n          10  0  0  0  0  0  0  0  0  0 19\n```\n:::\n\n```{.r .cell-code}\n#Median Absolute Error\n\nmdae_rf1.final <- mdae(test.class.n, rf1.pred)\nprint(mdae_rf1.final)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\nIt is important to mention that Median Absolute Error is not the ideal metric for Random Forest performance, it is more common using Accuracy, F1 Score, Precision, ROC AUC, Recall, etc. MdAE is more appropiate for regression type of method (instead of classification), however if I need to use the same metric for all methods, MdAE is feasible.\n\nNow model 2 (mtry=10 and trees=300)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#fit the model 2\n\nrf2 <- rand_forest(mtry=10, trees=300) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\")\n\n\nrf_fit2 <- rf2 %>%\n  fit(class.decile ~ ., data = test.n2)\n\n#Predict on the test set using first parameters:\n\ntest_pred2 <-  rf_fit2 %>%\n  predict(test.n2) %>%\n  bind_cols(test.n2) %>%\n  select(class.decile, .pred_class)\n\ntest_pred2 %>%\n    my_metrics(truth = class.decile, estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1  3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 f_meas  macro          0.990\n```\n:::\n\n```{.r .cell-code}\nrf2.pred2 <- test_pred2$.pred_class\nrf2.pred2 <- as.numeric(rf2.pred2)\ntest.class.n2 <- as.numeric(test.class)\n\n#Let's see the consufion matrix\nconfusion_matrix2 <- table(test.class.n, rf2.pred2)\nconfusion_matrix2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            rf2.pred2\ntest.class.n  1  2  3  4  5  6  7  8  9 10\n          1  20  0  0  0  0  0  0  0  0  0\n          2   0 19  0  0  0  0  0  0  0  0\n          3   0  0 19  0  0  0  0  0  0  0\n          4   0  0  0 19  0  0  0  0  0  0\n          5   0  0  0  0 18  0  0  0  1  0\n          6   0  0  0  0  0 18  0  0  1  0\n          7   0  0  0  0  0  0 19  0  0  0\n          8   0  0  0  0  0  0  0 19  0  0\n          9   0  0  0  0  0  0  0  0 19  0\n          10  0  0  0  0  0  0  0  0  0 19\n```\n:::\n\n```{.r .cell-code}\n#Median Absolute Error\n\nmdae_rf2.final <- mdae(test.class.n, rf2.pred2)\nprint(mdae_rf2.final)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\n# Section 6 - Compare models\n\nCompare and evaluate the models in terms of overfitting vs underfitting, bias vs variance tradeoff, flexibility vs interpretability.\n\nHere a summary of the Median Absolute Errors for each model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example objects\nMdAE_Linear_Regression_Model_1 <- c(135968120)\nMdAE_Linear_Regression_Model_3 <- c(123474556)\nMdAE_Lasso <- c(113643028)\nMdAE_RF_1 <- c(0)\nMdAE_RF_2 <- c(0)\n\n\n# Create a data frame\nmodels.table <- data.frame(\"MdAE Linear Regression Model1\" = MdAE_Linear_Regression_Model_1, \"MdAE Linear Regression Model3\" = MdAE_Linear_Regression_Model_3, \"MdAE Lasso\" = MdAE_Lasso, \"MdAE RF1\" = MdAE_RF_1, \"MdAE RF2\" = MdAE_RF_2)\n\n# Print the data frame with kable\nprint(models.table)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  MdAE.Linear.Regression.Model1 MdAE.Linear.Regression.Model3 MdAE.Lasso\n1                     135968120                     123474556  113643028\n  MdAE.RF1 MdAE.RF2\n1        0        0\n```\n:::\n:::\n\n\nThe first thing to note here is that the absolute error in the hundred millions seems high to me, overall the variables in the different models while explain a good proportion of the number of streams the performance doesn's seems the best to me.\n\nThe above statement seems not applying to the Random Forest method which has a zero error but this could mean a overfitting, even trying different hyperparameters it ended in almost zero error. Perhaps when classifying the number streams in 10 categories based on deciles of the distribution facilitate the prediction. Still it does sound like a overfitting.\n\nThen linear regression and lasso a more balanced model, with a more \"reasonable\" error iwhile high, and offers better interpretability by simplifying the model.\n\nThen among linear and lasso regression, seems that Linear Model 3 offer a good model in terms of simplicity and performance compared to linear model 1 (lower error and less predictors).\n\nLasso seems to offers a lot more interpretability without being too much underfitting. This model uses only 3 main variables and have the lowest Median Absolute Error (besides Random Forest). However even though doesn't seems underfitting too much (by judging for the MdAE), it can be too simple so maybe it can imply biased model.\n\n# Section 7 - Ethical implications\n\nIn the case of this model and what I have been trying to do which is predict number of songs streams, and based on the features collected in this dataset (nothing seems too personal in te data collected), I don't see a big ethical risks here.\n\nHowever, as all the marketing research analysis, at the end, it may result on manipulation of the user to generate more engagement in the platform which at the end is probably the end goal of music streaming platforms: more engagement for the users to spend more time in the platform.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}